{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69acef4b-0831-4e91-96ee-546919926cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import random \n",
    "import spacy\n",
    "import datasets \n",
    "import torchtext\n",
    "import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7472dd1-a9d7-4001-ae38-49895f7741c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# 确保程序的每次运行都具有确定性，可以得到相同的结果，用于程序的复现\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afecec32-1bcf-4803-888c-0e9ca5eac075",
   "metadata": {},
   "source": [
    "#### Preparing Data\n",
    "- 获取数据集\n",
    "- tokenize, 加入special tokens\n",
    "- train_data's vocabulary\n",
    "- numerialize\n",
    "- with_format 修改index的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73816e8a-cd29-4f1a-98fc-2ff107c285aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"bentrevett/multi30k\")\n",
    "# print(dataset)\n",
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7517ffda-73aa-4eec-8e85-ceabcc513d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'Two young, White males are outside near many bushes.', 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集每条数据是一个字典，key：语种，value：对应的句子\n",
    "print(train_data[0])\n",
    "type(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6380ed-69ff-4402-af9e-e905a3a9cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "# token一种更为笼统的说法，包含了words, numbers, punctuations, any special symbol\n",
    "# 利用spacy库加载两个用来处理德语/英语的模型\n",
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce9b7a1-a4ff-4246-9b9f-23e18cf80d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"What a lovely day it is today!\"\n",
    "[token.text for token in en_nlp.tokenizer(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fccea79d-0b8d-4db6-ba2f-d72ebbe82ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数 接收example数据，对应的处理器，最大的长度，是否lower，句子的开始结尾token\n",
    "def tokenizer_example(example, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\" : en_tokens, \"de_tokens\" : de_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa2c450-3d80-47a6-9770-3695659e000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "lower = True \n",
    "\n",
    "# function_keyword_arguments\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\" : en_nlp,\n",
    "    \"de_nlp\" : de_nlp,\n",
    "    \"max_length\" : max_length,\n",
    "    \"lower\" : lower,\n",
    "    \"sos_token\" : sos_token,\n",
    "    \"eos_token\" : eos_token,\n",
    "}\n",
    "\n",
    "# 通过调用tokenizer_example函数并传入对应的参数字典，来向dataset中添加函数返回的key-value\n",
    "train_data = train_data.map(tokenizer_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenizer_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenizer_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468be608-340d-4605-bbe7-e6f1e0802354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c208bee-63c1-4107-ad23-5a8760cb798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabularies \n",
    "# 生成token和index之间的映射字典，传入神经网络的是这些映射整数\n",
    "# 理论上说，生成的字母表应该包含所有可能出现的token，但是如果token不出现在train_data中但是出现在test_data或者valid_data中呢\n",
    "# 引入<unk> unkown token，其对应的index通常是一个固定的数，比如0，用来表示那些在vocabulary中无法找到的token\n",
    "\n",
    "# 出现次数小于min_freq的应该被tokenize为<unk>，人为在train_data中添加了<unk>的token\n",
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "# 每次输入一个batch，batch中的句子长度应该在传入时与这一批中的最大长度相同，转化为token时自动padding\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "]\n",
    "\n",
    "# vocabulary 只能在train_data上建立，防止信息泄露\n",
    "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "de_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"de_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a498deed-ee67-4026-9f12-31851c57c0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', '<eos>', '<unk>', '<pad>', 'a', '.', 'in', 'the', 'on', 'man']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这表示int to string的前十个，可以切片，因为是存在list中\n",
    "en_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a9ebf6-198e-4a8f-911c-375e22fbe6d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 1869,\n",
       " 'metal': 307,\n",
       " 'green': 52,\n",
       " 'track': 302,\n",
       " 'pours': 2356,\n",
       " 'vase': 5829,\n",
       " 'the': 7,\n",
       " 'crashes': 3951,\n",
       " 'non': 5340,\n",
       " 'bonding': 4685,\n",
       " 'face': 158,\n",
       " 'doll': 1775,\n",
       " 'garbage': 1120,\n",
       " 'workers': 228,\n",
       " 'winter': 446,\n",
       " 'taste': 3737,\n",
       " 'seems': 1207,\n",
       " 'outdoors': 341,\n",
       " 'her': 44,\n",
       " 'activity': 1973,\n",
       " 'hose': 834,\n",
       " 'turbulent': 5808,\n",
       " 'group': 38,\n",
       " 'gentleman': 524,\n",
       " 'bald': 683,\n",
       " 'underway': 4509,\n",
       " 'a': 4,\n",
       " 'scaffolds': 5551,\n",
       " 'outside': 57,\n",
       " 'drivers': 3393,\n",
       " 'readying': 3612,\n",
       " 'jeans': 175,\n",
       " 'black': 26,\n",
       " 'to': 18,\n",
       " 'jungle': 1235,\n",
       " 'supervision': 5722,\n",
       " 'or': 258,\n",
       " 'all': 255,\n",
       " 'examined': 4955,\n",
       " 'observes': 1725,\n",
       " 'i': 956,\n",
       " 'ball': 68,\n",
       " 'sandwich': 1293,\n",
       " '<sos>': 0,\n",
       " 'cheerleaders': 927,\n",
       " 'fisherman': 1421,\n",
       " 'firetruck': 1419,\n",
       " 'sunrise': 3726,\n",
       " 'pub': 2816,\n",
       " 'fires': 4989,\n",
       " 'sing': 1209,\n",
       " 'street': 39,\n",
       " 'moped': 1504,\n",
       " 'in': 6,\n",
       " 'customers': 850,\n",
       " 'sheepdog': 3654,\n",
       " 'taping': 5747,\n",
       " 'mood': 5309,\n",
       " 'attire': 453,\n",
       " 'kicked': 2761,\n",
       " 'probably': 2812,\n",
       " 'soccer': 123,\n",
       " '<pad>': 3,\n",
       " 'crane': 1480,\n",
       " 'smoke': 1346,\n",
       " 'york': 1105,\n",
       " 'lowering': 5250,\n",
       " 'hiding': 2022,\n",
       " 'cowboy': 429,\n",
       " 'storage': 3710,\n",
       " 'daily': 2466,\n",
       " 'kimono': 5199,\n",
       " 'cottage': 4837,\n",
       " '<eos>': 1,\n",
       " '.': 5,\n",
       " 'woods': 440,\n",
       " 'little': 53,\n",
       " 'newspapers': 1802,\n",
       " '<unk>': 2,\n",
       " 'pushes': 940,\n",
       " 'presses': 4305,\n",
       " 'moved': 4223,\n",
       " 'burning': 1858,\n",
       " 'helicopter': 2021,\n",
       " 'water': 47,\n",
       " 'accompanies': 3818,\n",
       " 'raises': 1518,\n",
       " 'decorations': 2126,\n",
       " 'toast': 3754,\n",
       " 'girls': 104,\n",
       " 'crashing': 2280,\n",
       " 'on': 8,\n",
       " 'motorbike': 1505,\n",
       " 'again': 3826,\n",
       " 'slides': 1345,\n",
       " 'produce': 893,\n",
       " 'district': 4903,\n",
       " 'brown': 61,\n",
       " 'flowers': 367,\n",
       " 'writing': 680,\n",
       " 'together': 129,\n",
       " 'walkway': 679,\n",
       " 'subject': 5715,\n",
       " 'strange': 1948,\n",
       " 'gymnasium': 1495,\n",
       " 'squares': 3695,\n",
       " 'dancing': 239,\n",
       " 'flips': 1708,\n",
       " 'math': 5276,\n",
       " 'sitting': 32,\n",
       " 'eagle': 4925,\n",
       " 'coeds': 4803,\n",
       " 'adult': 387,\n",
       " 'stunt': 823,\n",
       " 'horses': 494,\n",
       " 'man': 9,\n",
       " 'structures': 3717,\n",
       " 'swamp': 5733,\n",
       " 'dolly': 3385,\n",
       " 'near': 80,\n",
       " 'cart': 271,\n",
       " 'airplane': 1016,\n",
       " 'playing': 37,\n",
       " 'shake': 4389,\n",
       " 'forehead': 1781,\n",
       " 'other': 72,\n",
       " 'mittens': 2782,\n",
       " 'punching': 2563,\n",
       " 'fountain': 383,\n",
       " 'down': 40,\n",
       " 'short': 386,\n",
       " 'companion': 2278,\n",
       " 'standing': 36,\n",
       " 'tee': 1671,\n",
       " 'appears': 477,\n",
       " 'woman': 14,\n",
       " 'merchant': 3109,\n",
       " 'mob': 5304,\n",
       " 'tired': 2228,\n",
       " 'poses': 436,\n",
       " 'plaid': 384,\n",
       " 'balls': 810,\n",
       " 'is': 10,\n",
       " 'band': 200,\n",
       " 'white': 25,\n",
       " 'an': 21,\n",
       " 'curly': 867,\n",
       " 'helping': 727,\n",
       " 'traffic': 783,\n",
       " 'chili': 4768,\n",
       " 'and': 11,\n",
       " 'conversation': 566,\n",
       " 'sorts': 3684,\n",
       " 'moose': 4219,\n",
       " 'outfit': 300,\n",
       " 'being': 191,\n",
       " 'sprinklers': 2863,\n",
       " 'of': 12,\n",
       " 'bike': 99,\n",
       " 'swing': 308,\n",
       " 'bottle': 531,\n",
       " 'wooded': 902,\n",
       " 'sees': 4380,\n",
       " 'apart': 1976,\n",
       " 'ladder': 576,\n",
       " 'yellow': 62,\n",
       " 'technique': 3742,\n",
       " 'enthusiastically': 3407,\n",
       " 'leaves': 513,\n",
       " 'dog': 35,\n",
       " 'proud': 4314,\n",
       " 'squatting': 1394,\n",
       " 'barriers': 2660,\n",
       " 'open': 310,\n",
       " 'seated': 450,\n",
       " 'door': 532,\n",
       " 'flotation': 4060,\n",
       " 'ribbon': 1441,\n",
       " 'siding': 3658,\n",
       " 'after': 376,\n",
       " 'acrobat': 4569,\n",
       " 'with': 13,\n",
       " 'men': 30,\n",
       " 'slip': 3669,\n",
       " 'fashionable': 3415,\n",
       " ',': 15,\n",
       " 'taxi': 1596,\n",
       " 'hikers': 932,\n",
       " 'two': 16,\n",
       " 'friend': 851,\n",
       " 'as': 58,\n",
       " 'await': 2426,\n",
       " 'blue': 29,\n",
       " 'medals': 5280,\n",
       " 'are': 17,\n",
       " 'people': 19,\n",
       " 'boards': 1983,\n",
       " 'slope': 944,\n",
       " 'at': 20,\n",
       " 'chopsticks': 2115,\n",
       " 'flies': 831,\n",
       " 'beards': 3295,\n",
       " 'thought': 3749,\n",
       " 'amusement': 1182,\n",
       " 'children': 63,\n",
       " 'interested': 4129,\n",
       " 'meat': 740,\n",
       " 'hooded': 1161,\n",
       " 'buildings': 470,\n",
       " 'wearing': 22,\n",
       " 'shirt': 23,\n",
       " 'frisbee': 409,\n",
       " 'raise': 2822,\n",
       " 'pushing': 410,\n",
       " 'three': 48,\n",
       " 'chores': 4777,\n",
       " 'into': 69,\n",
       " 't': 208,\n",
       " 'tour': 2398,\n",
       " 'laid': 2514,\n",
       " 'fish': 442,\n",
       " 'trail': 438,\n",
       " 'fetch': 2494,\n",
       " 'sloping': 3670,\n",
       " 'shouts': 5607,\n",
       " 'without': 879,\n",
       " 'fallen': 974,\n",
       " 'sculptor': 3644,\n",
       " 'girl': 33,\n",
       " 'boutique': 4693,\n",
       " 'young': 24,\n",
       " 'punch': 2360,\n",
       " 'ponchos': 4294,\n",
       " 'play': 128,\n",
       " 'overweight': 1729,\n",
       " 'backpack': 343,\n",
       " 'james': 5182,\n",
       " 'nicely': 3119,\n",
       " 'his': 27,\n",
       " 'here': 832,\n",
       " 'tux': 5811,\n",
       " 'herself': 1324,\n",
       " 'toward': 458,\n",
       " 'stilts': 2069,\n",
       " 'skeleton': 3663,\n",
       " 'ladders': 3490,\n",
       " 'home': 545,\n",
       " 'while': 28,\n",
       " 'pot': 1001,\n",
       " 'mouth': 203,\n",
       " 'propeller': 5460,\n",
       " 'red': 31,\n",
       " 'makeshift': 3100,\n",
       " 'brother': 1986,\n",
       " 'uses': 579,\n",
       " 'filed': 4984,\n",
       " 'completing': 2456,\n",
       " 'boy': 34,\n",
       " 'computer': 418,\n",
       " 'riding': 78,\n",
       " 'facility': 2010,\n",
       " '-': 42,\n",
       " 'scattered': 2840,\n",
       " 'beneath': 1537,\n",
       " 'swimsuit': 1101,\n",
       " 'boats': 1110,\n",
       " 'walking': 41,\n",
       " 'course': 701,\n",
       " 'skin': 4402,\n",
       " 'photography': 3565,\n",
       " 'rows': 1936,\n",
       " 'container': 1366,\n",
       " 'skirt': 451,\n",
       " 'made': 730,\n",
       " 'joggers': 3479,\n",
       " 'race': 164,\n",
       " 'olympic': 2176,\n",
       " 'front': 43,\n",
       " 'crabs': 4842,\n",
       " 'for': 54,\n",
       " 'haired': 210,\n",
       " 'missed': 5300,\n",
       " 'belt': 1403,\n",
       " 'campers': 2963,\n",
       " 'wool': 3805,\n",
       " 'corner': 406,\n",
       " 'special': 2861,\n",
       " 'cow': 928,\n",
       " 'painter': 2178,\n",
       " 'manner': 5261,\n",
       " 'holding': 45,\n",
       " 'referee': 1206,\n",
       " 'drinking': 351,\n",
       " 'discussing': 1484,\n",
       " 'artwork': 1853,\n",
       " 'kiddie': 3484,\n",
       " 'one': 46,\n",
       " 'hot': 600,\n",
       " 'designs': 2128,\n",
       " 'cityscape': 2984,\n",
       " 'cups': 1697,\n",
       " 'smiles': 346,\n",
       " 'by': 49,\n",
       " 'large': 59,\n",
       " 'still': 1828,\n",
       " 'graduation': 3446,\n",
       " 'sort': 688,\n",
       " 'women': 50,\n",
       " 'loaded': 2331,\n",
       " 'flame': 4993,\n",
       " 'up': 51,\n",
       " 'geese': 4075,\n",
       " 'rise': 4354,\n",
       " 'driving': 506,\n",
       " 'tags': 2220,\n",
       " 'science': 1816,\n",
       " 'child': 55,\n",
       " 'friends': 486,\n",
       " 'stone': 333,\n",
       " 'apparatus': 2917,\n",
       " 'through': 60,\n",
       " 'looking': 56,\n",
       " 'assorted': 4619,\n",
       " 'number': 448,\n",
       " 'darth': 4871,\n",
       " 'cooked': 3356,\n",
       " 'hand': 139,\n",
       " 'material': 1564,\n",
       " 'person': 64,\n",
       " 'bmx': 1185,\n",
       " 'from': 65,\n",
       " 'substance': 3720,\n",
       " 'backwards': 1108,\n",
       " 'arm': 394,\n",
       " 'times': 2395,\n",
       " 'surfboard': 649,\n",
       " 'kid': 348,\n",
       " 'pocket': 2354,\n",
       " 'plush': 3148,\n",
       " 'europe': 2294,\n",
       " 'toy': 223,\n",
       " 'firefighters': 1227,\n",
       " 'ally': 3830,\n",
       " 'wet': 586,\n",
       " 'motion': 2172,\n",
       " 'excitement': 3036,\n",
       " 'pork': 5438,\n",
       " 'their': 66,\n",
       " 'perform': 508,\n",
       " 'scouts': 1939,\n",
       " 'hat': 67,\n",
       " 'enjoying': 304,\n",
       " 'baked': 2936,\n",
       " 'small': 70,\n",
       " 'aged': 433,\n",
       " 'handrail': 2019,\n",
       " 'next': 71,\n",
       " 'cafe': 720,\n",
       " 'buys': 4733,\n",
       " 'handing': 1785,\n",
       " 'orchestra': 1202,\n",
       " 'beach': 88,\n",
       " 'rowers': 4361,\n",
       " 'dressed': 73,\n",
       " 'button': 950,\n",
       " 'shoppers': 1822,\n",
       " 'berlin': 3877,\n",
       " 'rodgers': 5526,\n",
       " 'chin': 2453,\n",
       " 'country': 664,\n",
       " 'lecture': 1795,\n",
       " 'flute': 1709,\n",
       " 'coach': 1314,\n",
       " 'desks': 2471,\n",
       " 'some': 74,\n",
       " 'goods': 1121,\n",
       " 'river': 309,\n",
       " 'hardwood': 2313,\n",
       " 'out': 75,\n",
       " 'lion': 2520,\n",
       " 'ride': 281,\n",
       " 'items': 581,\n",
       " 'talk': 689,\n",
       " 'listens': 1502,\n",
       " 'quaint': 3606,\n",
       " 'over': 76,\n",
       " 'downtown': 1546,\n",
       " 'bump': 4721,\n",
       " 'building': 77,\n",
       " 'horseback': 1326,\n",
       " 'balancing': 1044,\n",
       " 'freight': 5016,\n",
       " 'tattoo': 825,\n",
       " 'island': 3080,\n",
       " 'swimmers': 1595,\n",
       " 'running': 79,\n",
       " 'around': 83,\n",
       " 'escalator': 1157,\n",
       " 'facade': 4038,\n",
       " 'lost': 3096,\n",
       " 'police': 362,\n",
       " 'mrs.': 5319,\n",
       " 'pinstriped': 3147,\n",
       " 'varying': 3249,\n",
       " 'jacket': 81,\n",
       " 'rides': 241,\n",
       " 'talks': 540,\n",
       " 'keyboard': 1088,\n",
       " 'amongst': 1533,\n",
       " 'another': 82,\n",
       " 'participants': 3555,\n",
       " 'inner': 4128,\n",
       " 'sidewalk': 84,\n",
       " 'column': 2697,\n",
       " 'mike': 4212,\n",
       " 'field': 85,\n",
       " 'kayaker': 3480,\n",
       " 'african': 324,\n",
       " 'orange': 86,\n",
       " 'cast': 2973,\n",
       " 'camera': 116,\n",
       " 'shops': 1660,\n",
       " 'crowd': 87,\n",
       " 'denim': 1049,\n",
       " 'downwards': 4910,\n",
       " 'photos': 1576,\n",
       " 'stands': 89,\n",
       " 'beverages': 1762,\n",
       " 'bikini': 590,\n",
       " 'dunk': 3398,\n",
       " 'inside': 280,\n",
       " 'lens': 2031,\n",
       " 'pink': 90,\n",
       " 'sprinkled': 4429,\n",
       " 'hula': 886,\n",
       " 'topic': 3755,\n",
       " 'sits': 91,\n",
       " 'soldering': 3679,\n",
       " 'pushed': 2817,\n",
       " 'pose': 403,\n",
       " 'supermarket': 2605,\n",
       " 'doorstep': 4907,\n",
       " 'tag': 1349,\n",
       " 'jumping': 92,\n",
       " 'skinned': 1099,\n",
       " 'printed': 1929,\n",
       " 'behind': 93,\n",
       " 'table': 94,\n",
       " 'rink': 1442,\n",
       " 'looks': 107,\n",
       " 'decker': 3971,\n",
       " 'cellphone': 286,\n",
       " 'fives': 3423,\n",
       " 'snow': 95,\n",
       " 'grass': 96,\n",
       " 'teammate': 1597,\n",
       " 'lined': 474,\n",
       " 'hair': 97,\n",
       " 'puppies': 1811,\n",
       " 'spin': 3693,\n",
       " 'hardware': 5085,\n",
       " 'bench': 144,\n",
       " 'win': 2415,\n",
       " 'instruments': 423,\n",
       " 'background': 98,\n",
       " 'examining': 1191,\n",
       " 'stunning': 5711,\n",
       " 'father': 665,\n",
       " 'clap': 2692,\n",
       " 'projector': 2358,\n",
       " 'scuba': 1248,\n",
       " 'sand': 211,\n",
       " 'mixture': 5302,\n",
       " 'downward': 4909,\n",
       " 'photo': 342,\n",
       " 'stand': 100,\n",
       " 'city': 101,\n",
       " 'tap': 3736,\n",
       " 'clear': 1022,\n",
       " 'cotton': 2461,\n",
       " 'gas': 1493,\n",
       " 'yamaha': 3810,\n",
       " 'both': 405,\n",
       " 'bite': 1763,\n",
       " 'sweet': 4460,\n",
       " 'vehicle': 529,\n",
       " 'haircut': 1229,\n",
       " \"'s\": 102,\n",
       " 'air': 103,\n",
       " 'wigs': 3802,\n",
       " 'nap': 1130,\n",
       " 'work': 245,\n",
       " 'filling': 1780,\n",
       " 'written': 2905,\n",
       " 'younger': 530,\n",
       " 'wakeboards': 5849,\n",
       " 'tugging': 3241,\n",
       " 'player': 105,\n",
       " 'dragster': 4911,\n",
       " 'marathon': 644,\n",
       " 'positioned': 3152,\n",
       " 'security': 1588,\n",
       " 'gathered': 359,\n",
       " 'luggage': 1029,\n",
       " 'asian': 106,\n",
       " 'cheers': 3925,\n",
       " 'cap': 283,\n",
       " '2': 417,\n",
       " 'signs': 696,\n",
       " 'cheek': 1865,\n",
       " 'wall': 108,\n",
       " 'top': 109,\n",
       " 'buoy': 3318,\n",
       " 'dance': 330,\n",
       " 'east': 2136,\n",
       " 'dark': 178,\n",
       " 'ballet': 1758,\n",
       " 'screwdriver': 4376,\n",
       " 'four': 110,\n",
       " 'excited': 1415,\n",
       " 'rodeo': 560,\n",
       " 'off': 111,\n",
       " 'released': 4341,\n",
       " 'opens': 1917,\n",
       " 'took': 4479,\n",
       " 'dogs': 112,\n",
       " 'gift': 1630,\n",
       " 'mechanic': 3515,\n",
       " 'several': 113,\n",
       " 'strike': 2869,\n",
       " 'elmo': 2138,\n",
       " 'that': 114,\n",
       " 'jogging': 854,\n",
       " 'older': 115,\n",
       " 'sleeps': 822,\n",
       " 'taking': 165,\n",
       " 'reporters': 5508,\n",
       " 'arcade': 1852,\n",
       " 'toil': 5782,\n",
       " 'this': 209,\n",
       " 'mix': 2337,\n",
       " 'eight': 1269,\n",
       " 'airport': 1148,\n",
       " 'it': 141,\n",
       " 'wicker': 3801,\n",
       " 'dress': 117,\n",
       " 'warming': 2631,\n",
       " 'audio': 3850,\n",
       " 'park': 118,\n",
       " 'talking': 119,\n",
       " 'weeds': 3795,\n",
       " 'students': 521,\n",
       " 'rocket': 5525,\n",
       " 'lady': 120,\n",
       " 'five': 251,\n",
       " 'apron': 502,\n",
       " 'sunlight': 1949,\n",
       " 'burgundy': 1686,\n",
       " 'quickly': 2055,\n",
       " 'pump': 4319,\n",
       " 'something': 121,\n",
       " 'handbag': 2746,\n",
       " 'rose': 5529,\n",
       " 'blond': 122,\n",
       " 'chases': 951,\n",
       " 'art': 511,\n",
       " 'along': 124,\n",
       " 'last': 3088,\n",
       " 'binder': 4666,\n",
       " 'cobblestone': 1621,\n",
       " 'dreadlocks': 1413,\n",
       " 'oriental': 937,\n",
       " 'mugs': 5320,\n",
       " 'devil': 4890,\n",
       " 'walks': 125,\n",
       " 'outfits': 693,\n",
       " 'between': 412,\n",
       " 'grill': 507,\n",
       " 'facing': 618,\n",
       " 'individuals': 835,\n",
       " 'express': 4961,\n",
       " 'guitar': 126,\n",
       " 'washing': 760,\n",
       " 'trying': 260,\n",
       " 'mesmerized': 4207,\n",
       " 'theater': 1527,\n",
       " 'van': 809,\n",
       " 'oh': 5354,\n",
       " 'attempting': 682,\n",
       " 'boys': 127,\n",
       " 'working': 130,\n",
       " 'during': 226,\n",
       " 'aprons': 2090,\n",
       " 'tattered': 3739,\n",
       " 'islamic': 5174,\n",
       " 'food': 131,\n",
       " 'mud': 741,\n",
       " 'purses': 2361,\n",
       " 'champagne': 2978,\n",
       " 'textile': 5760,\n",
       " 'gray': 132,\n",
       " 'process': 2052,\n",
       " 'sexy': 4385,\n",
       " 'bagpipes': 1757,\n",
       " 'shrimp': 4393,\n",
       " 'mother': 496,\n",
       " 'surgery': 1951,\n",
       " 'smiling': 133,\n",
       " 'sweater': 317,\n",
       " 'tan': 282,\n",
       " 'watering': 2895,\n",
       " 'book': 277,\n",
       " 'films': 4048,\n",
       " 'picture': 134,\n",
       " 'getting': 257,\n",
       " 'inspectors': 5160,\n",
       " 'hammer': 992,\n",
       " 'straight': 1669,\n",
       " 'binoculars': 1614,\n",
       " 'game': 135,\n",
       " 'treat': 2230,\n",
       " 'completes': 4815,\n",
       " 'has': 136,\n",
       " 'member': 1435,\n",
       " 'mug': 1915,\n",
       " 'sleeveless': 1445,\n",
       " 'walk': 152,\n",
       " 'including': 871,\n",
       " 'masonry': 5269,\n",
       " 'fed': 4042,\n",
       " 'reaching': 780,\n",
       " 'series': 2367,\n",
       " 'plays': 137,\n",
       " 'china': 1867,\n",
       " 'cliff': 479,\n",
       " 'resting': 841,\n",
       " 'operated': 2795,\n",
       " 'wheelchair': 1070,\n",
       " 'sun': 427,\n",
       " 'car': 138,\n",
       " 'kissing': 659,\n",
       " 'locomotives': 5243,\n",
       " 'holds': 140,\n",
       " 'skier': 648,\n",
       " 'grabbing': 2149,\n",
       " 'cones': 1047,\n",
       " 'vertical': 3251,\n",
       " 'reading': 218,\n",
       " 'dancers': 747,\n",
       " 'road': 142,\n",
       " 'ended': 4939,\n",
       " 'carriage': 1113,\n",
       " 'house': 356,\n",
       " 'think': 3747,\n",
       " 'package': 2348,\n",
       " 'climbs': 643,\n",
       " 'free': 1424,\n",
       " 'featured': 4041,\n",
       " 'laying': 273,\n",
       " 'beating': 2432,\n",
       " 'beard': 441,\n",
       " 'him': 143,\n",
       " 'path': 288,\n",
       " 'padding': 3549,\n",
       " 'chasing': 656,\n",
       " 'award': 2656,\n",
       " 'old': 145,\n",
       " 'knees': 1793,\n",
       " 'angels': 2914,\n",
       " 'rural': 1443,\n",
       " 'glasses': 146,\n",
       " 'skate': 744,\n",
       " 'peeling': 3564,\n",
       " 'francisco': 5013,\n",
       " 'night': 305,\n",
       " 'oxen': 3547,\n",
       " 'very': 262,\n",
       " 'late': 2766,\n",
       " 'bikes': 449,\n",
       " 'vegas': 3780,\n",
       " 'bathed': 3865,\n",
       " 'pants': 147,\n",
       " 'tutus': 4501,\n",
       " 'pulling': 475,\n",
       " 'toss': 4481,\n",
       " 'shorts': 148,\n",
       " 'stage': 149,\n",
       " 'enthusiastic': 4947,\n",
       " 'sit': 150,\n",
       " 'view': 428,\n",
       " 'cupcakes': 3369,\n",
       " 'carrying': 151,\n",
       " 'microphone': 220,\n",
       " 'poised': 3580,\n",
       " 'watched': 1968,\n",
       " 'baby': 153,\n",
       " 'couple': 154,\n",
       " 'competing': 617,\n",
       " 'boarding': 2668,\n",
       " 'celebrating': 1362,\n",
       " 'them': 155,\n",
       " 'shallow': 792,\n",
       " 'swaddled': 5731,\n",
       " 'village': 1605,\n",
       " 'paddled': 5373,\n",
       " 'plastic': 431,\n",
       " 'carpeted': 3328,\n",
       " 'fashioned': 1887,\n",
       " 'sunhat': 3725,\n",
       " 'side': 156,\n",
       " 'forrest': 4066,\n",
       " 'ornate': 1383,\n",
       " 'bicycle': 157,\n",
       " 'meal': 596,\n",
       " 'mini': 2532,\n",
       " 'swims': 983,\n",
       " 'jack': 2757,\n",
       " 'no': 549,\n",
       " 'lipstick': 2771,\n",
       " 'maneuvering': 4191,\n",
       " 'knife': 1794,\n",
       " 'bun': 4722,\n",
       " 'turn': 967,\n",
       " 'jerseys': 1124,\n",
       " 'tree': 159,\n",
       " 'similarly': 3660,\n",
       " 'dust': 1777,\n",
       " '\"': 160,\n",
       " 'male': 161,\n",
       " 'pool': 162,\n",
       " 'flashlight': 4054,\n",
       " 'grin': 5061,\n",
       " 'long': 163,\n",
       " 'blocked': 2949,\n",
       " 'rock': 166,\n",
       " 'court': 493,\n",
       " 'each': 167,\n",
       " 'rad': 5476,\n",
       " 'coached': 4797,\n",
       " 'wood': 424,\n",
       " 'quietly': 5472,\n",
       " 'headscarf': 1278,\n",
       " 'touch': 1957,\n",
       " 'where': 476,\n",
       " 'middle': 168,\n",
       " 'opposite': 1030,\n",
       " 'doing': 169,\n",
       " 'british': 2440,\n",
       " 'equestrian': 3034,\n",
       " 'pillow': 1651,\n",
       " 'robes': 1006,\n",
       " 'public': 420,\n",
       " 'dirt': 170,\n",
       " 'half': 1276,\n",
       " 'across': 171,\n",
       " 'tables': 708,\n",
       " 'head': 172,\n",
       " 'vests': 468,\n",
       " 'paris': 5385,\n",
       " 'barrier': 1682,\n",
       " 'forest': 397,\n",
       " 'watching': 173,\n",
       " 'coveralls': 3359,\n",
       " 'bystanders': 1687,\n",
       " 'crown': 2709,\n",
       " 'heads': 768,\n",
       " 'rice': 1934,\n",
       " 'guy': 174,\n",
       " 'beanie': 1760,\n",
       " 'seesaw': 3181,\n",
       " 'bmw': 3882,\n",
       " 'there': 176,\n",
       " 'area': 177,\n",
       " 'motorcyclists': 1912,\n",
       " 'skateboarder': 480,\n",
       " 'strapped': 2216,\n",
       " 'room': 187,\n",
       " 'jumps': 179,\n",
       " 'photographers': 2352,\n",
       " 'fuzzy': 2504,\n",
       " 'dirty': 765,\n",
       " 'dj': 1880,\n",
       " 'waring': 3788,\n",
       " 'despite': 3381,\n",
       " 'boat': 180,\n",
       " 'numbers': 2042,\n",
       " 'pony': 2355,\n",
       " 'hands': 181,\n",
       " 'emergency': 1487,\n",
       " 'swampy': 3730,\n",
       " 'many': 202,\n",
       " 'back': 182,\n",
       " 'boxers': 2674,\n",
       " 'female': 183,\n",
       " 'whistle': 2900,\n",
       " 'cement': 626,\n",
       " 'rowing': 1292,\n",
       " 'day': 184,\n",
       " 'shopping': 332,\n",
       " 'papers': 1573,\n",
       " 'alley': 641,\n",
       " 'storefronts': 3213,\n",
       " 'eyeliner': 4964,\n",
       " 'ground': 185,\n",
       " 'driveway': 2006,\n",
       " 'performing': 186,\n",
       " 'fun': 816,\n",
       " 'second': 1940,\n",
       " 'applying': 1755,\n",
       " 'curious': 3370,\n",
       " 'dinner': 884,\n",
       " 'parachutes': 3130,\n",
       " 'karaoke': 4143,\n",
       " 'interior': 4130,\n",
       " 'window': 240,\n",
       " 'emerges': 3033,\n",
       " 'places': 1809,\n",
       " 'shows': 821,\n",
       " 'baseball': 188,\n",
       " 'stripes': 1454,\n",
       " 'waterway': 1749,\n",
       " 'lane': 1329,\n",
       " 'pointing': 609,\n",
       " 'movie': 1800,\n",
       " 'what': 459,\n",
       " 'pitching': 2805,\n",
       " 'light': 299,\n",
       " 'turkey': 2621,\n",
       " 'money': 1198,\n",
       " 'who': 189,\n",
       " 'muscular': 2342,\n",
       " 'shapes': 3651,\n",
       " 'eggs': 1704,\n",
       " 'preparing': 370,\n",
       " 'sweatpants': 5736,\n",
       " 'leashed': 5223,\n",
       " 'eating': 190,\n",
       " 'selling': 395,\n",
       " 'barefooted': 2253,\n",
       " 'jackets': 555,\n",
       " 'football': 192,\n",
       " 'coat': 193,\n",
       " 'placed': 1923,\n",
       " 'foliage': 2144,\n",
       " 'fill': 2496,\n",
       " 'striped': 194,\n",
       " 'using': 195,\n",
       " 'pockets': 4290,\n",
       " 'kids': 196,\n",
       " 'toys': 773,\n",
       " 'machete': 4188,\n",
       " 'hard': 325,\n",
       " '%': 4557,\n",
       " 'baskets': 1306,\n",
       " 'leaps': 601,\n",
       " 'helmet': 234,\n",
       " 'devices': 2714,\n",
       " 'suit': 197,\n",
       " 'buck': 4711,\n",
       " 'indian': 554,\n",
       " 'breakfast': 3895,\n",
       " 'provide': 4316,\n",
       " 'horse': 198,\n",
       " 'structure': 520,\n",
       " 'progress': 2814,\n",
       " 'clothing': 219,\n",
       " 'lifted': 1903,\n",
       " 'seeds': 3648,\n",
       " 'under': 199,\n",
       " 'smelling': 5644,\n",
       " 'arena': 1017,\n",
       " 'faced': 4039,\n",
       " 'hatchet': 5089,\n",
       " 'tasty': 4466,\n",
       " 'main': 2775,\n",
       " 'watch': 201,\n",
       " 'fireplace': 3045,\n",
       " 'truck': 276,\n",
       " 'purple': 204,\n",
       " 'he': 205,\n",
       " 'fence': 268,\n",
       " 'restaurant': 235,\n",
       " 'spongebob': 3205,\n",
       " 'cars': 492,\n",
       " 'excitedly': 2723,\n",
       " 'mouse': 2784,\n",
       " 'way': 710,\n",
       " 'sign': 206,\n",
       " 'vacuuming': 2628,\n",
       " 'store': 207,\n",
       " 'calf': 1408,\n",
       " 'have': 414,\n",
       " 'runs': 212,\n",
       " 'tennis': 213,\n",
       " 'stops': 1829,\n",
       " 'look': 214,\n",
       " 'snowdrift': 5650,\n",
       " 'speak': 1947,\n",
       " 'players': 215,\n",
       " 'works': 465,\n",
       " 'interacting': 1636,\n",
       " 'neighborhood': 1335,\n",
       " 'ramp': 432,\n",
       " 'packs': 5372,\n",
       " 'school': 456,\n",
       " 'construction': 216,\n",
       " 'sunglasses': 217,\n",
       " 'towards': 301,\n",
       " 'reads': 455,\n",
       " 'content': 3941,\n",
       " 'michael': 5289,\n",
       " 'cyclist': 868,\n",
       " 'mountain': 221,\n",
       " 'observed': 4239,\n",
       " 'examines': 1706,\n",
       " 'mates': 3514,\n",
       " 'covered': 222,\n",
       " 'kissed': 4150,\n",
       " 'basketball': 224,\n",
       " 'gazes': 2017,\n",
       " 'bag': 265,\n",
       " 'ocean': 225,\n",
       " 'mower': 1914,\n",
       " 'slot': 3671,\n",
       " 'props': 5461,\n",
       " 'boaters': 4683,\n",
       " 'discuss': 2474,\n",
       " 'drink': 413,\n",
       " 'statue': 443,\n",
       " 'its': 227,\n",
       " 'nibbles': 5337,\n",
       " 'india': 2320,\n",
       " 'birthday': 1355,\n",
       " 'mule': 2785,\n",
       " 'motorcycle': 295,\n",
       " 'watches': 229,\n",
       " 'resort': 2573,\n",
       " 'protect': 2359,\n",
       " 'climbing': 230,\n",
       " 'soap': 2210,\n",
       " 'uniform': 231,\n",
       " 'past': 232,\n",
       " 'sedan': 4378,\n",
       " 'waiting': 254,\n",
       " 'seat': 1097,\n",
       " 'target': 1741,\n",
       " 'bat': 848,\n",
       " 'elderly': 233,\n",
       " 'gym': 726,\n",
       " 'sleeping': 375,\n",
       " 'pruning': 4317,\n",
       " 'tires': 1745,\n",
       " 'against': 236,\n",
       " 'powder': 3589,\n",
       " 'sunny': 396,\n",
       " 'formation': 1892,\n",
       " 'closely': 1868,\n",
       " 'garage': 1273,\n",
       " 'team': 237,\n",
       " 'train': 238,\n",
       " 'vision': 5839,\n",
       " 'filled': 473,\n",
       " 'unseen': 3775,\n",
       " 'link': 2034,\n",
       " 'skateboarding': 584,\n",
       " 'decked': 4877,\n",
       " 'shop': 316,\n",
       " 'bridge': 365,\n",
       " 'shirts': 242,\n",
       " 'lining': 2519,\n",
       " 'march': 2038,\n",
       " 'gentlemen': 975,\n",
       " 'protective': 1003,\n",
       " 'snaps': 3196,\n",
       " 'fold': 3430,\n",
       " 'chair': 243,\n",
       " 'surroundings': 3728,\n",
       " 'pitcher': 939,\n",
       " 'they': 244,\n",
       " 'bunny': 2680,\n",
       " 'hangs': 1025,\n",
       " 'about': 246,\n",
       " 'sips': 4398,\n",
       " 'tub': 1256,\n",
       " 'be': 247,\n",
       " 'see': 1007,\n",
       " 'collar': 721,\n",
       " 'diving': 748,\n",
       " 'canal': 2265,\n",
       " 'leave': 5224,\n",
       " 'teenage': 732,\n",
       " 'consoles': 4820,\n",
       " 'picnic': 916,\n",
       " 'blazer': 1981,\n",
       " 'exercise': 1778,\n",
       " 'mounds': 5314,\n",
       " 'engine': 1551,\n",
       " 'wooden': 248,\n",
       " 'wrestle': 1606,\n",
       " 'posing': 249,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 无法切片因为是dict\n",
    "en_vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ca29efd-3c75-4152-9cf3-b4b9d3d08646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_stoi()[\"in\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e4764cf-6dba-4925-825a-0abb2e97fc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还可以直接写成\n",
    "en_vocab[\"in\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8a39ea5-d94d-4145-a88a-42645fec3817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7853, 5893)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_vocab), len(en_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ff69c25-9c07-4c3a-ab79-2a7d86437f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# \"The\" 中含有大写字母一定不在en_vocab中\n",
    "print(\"The\" in en_vocab)\n",
    "# en_vocab[\"The\"] # 会报错，可以设置这个值，在取不存在与vocab中的单词时返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a28dec9-2d54-482d-84e8-380dda33ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab 中<unk>的index不一定是0，与specials参数中的顺序有关\n",
    "assert en_vocab[pad_token] == de_vocab[pad_token]\n",
    "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741a4240-e188-47b8-a764-471da8685eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上面在取vocabulary之外的值时，就会报错，这里设置默认的不在vocabulary中的token的index值为unk_index\n",
    "en_vocab.set_default_index(unk_index)\n",
    "de_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19b2e978-3f79-4710-aa12-2a8b6dc164ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[\"The\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb016c25-787a-4b49-84e8-1a46dd2f9e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[956, 2169, 173, 2, 821]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个有用的method，lookup_indeces，接收一个token list返回对应的index\n",
    "\n",
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "en_vocab.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ed88ea-16ce-4c3b-94e3-3b02a65a1d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'watching', '<unk>', 'shows']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 相应的lookup_tokens\n",
    "en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e214505a-cdbd-44ea-8c06-c0450fbcbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类似tokenize_example，写一个numericalize_example通过map应用\n",
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
    "    return {\"en_ids\" : en_ids, \"de_ids\" : de_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1cf3642-342f-43ff-9094-295d4829dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_kwargs 是function_keyword arguments的缩写\n",
    "fn_kwargs = {\"en_vocab\" : en_vocab, \"de_vocab\" : de_vocab}\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59ac6494-340a-4dd0-b2df-cd52a459fd40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'en_ids': [0, 16, 24, 15, 25, 778, 17, 57, 80, 202, 1312, 5, 1],\n",
       " 'de_ids': [0, 18, 26, 253, 30, 84, 20, 88, 7, 15, 110, 7647, 3171, 4, 1]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "390d81a1-16e6-4d1b-91f8-908c2c2c8ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'two',\n",
       " 'young',\n",
       " ',',\n",
       " 'white',\n",
       " 'males',\n",
       " 'are',\n",
       " 'outside',\n",
       " 'near',\n",
       " 'many',\n",
       " 'bushes',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查一些是否对应\n",
    "en_vocab.lookup_tokens(train_data[0]['en_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "646a72ba-b30c-46eb-8506-4b9fed6eb0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目前的index都是python的内置int类型，希望转化为\"torch\" for Pytorch\n",
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "# with_format method把对应的columns转化为type类型，默认是只返回columns中包含的features\n",
    "# 设置output_all_columns=True，可以保留所有的特征\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aa1e18c-bd27-41e2-ad9c-63721c780651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([   0,   16,   24,   15,   25,  778,   17,   57,   80,  202, 1312,    5,\n",
       "            1]),\n",
       " 'de_ids': tensor([   0,   18,   26,  253,   30,   84,   20,   88,    7,   15,  110, 7647,\n",
       "         3171,    4,    1]),\n",
       " 'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21ec31e5-708b-4919-8806-c84e690dd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个batch进行padding处理,collate means collect and combine\n",
    "\n",
    "# 传入的参数是用来padding的index，返回一个函数collate_fn\n",
    "# closure闭包的写法，让内部的函数能够持续地使用pad_index，而不用创建全局变量或者创建一个类\n",
    "def get_collate_fn(pad_index):\n",
    "    # 返回一个字典，分开的batch（两个语言分开），已经使用pad_index padding使得所有长度与原长度最大相等，传入的参数是一个batch大小的data\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example['en_ids'] for example in batch]\n",
    "        batch_de_ids = [example['de_ids'] for example in batch]\n",
    "        # batch_first=False（默认为False），返回的数据size就是[max_length, batch_size]的，也就是每一列是padding后的\n",
    "        # numericalize 的sequence，如果设置batch_first=True，那么返回的数据就是[batch_size, max_length]符合每一行是seq的直觉\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        return {\"en_ids\" : batch_en_ids, \"de_ids\" : batch_de_ids}\n",
    "    return collate_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d9588db-7fef-4de1-aa62-e672459f16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用Pytorch的DataLoader\n",
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81411ac8-b47e-4724-821f-957dd753cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了发挥最大性能，batch_size应该适合GPU的内存\n",
    "# 训练时数据设置为shuffle=True，可以得到更稳定的结果，valid和test上没必要shuffle\n",
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d987c5f-4584-4c95-bde8-d44030da96fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 展示数据表明被处理后的数据是按列排布的\n",
    "# for data in train_data_loader:\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22d3bb6a-8df8-4c41-9c98-96b822d453c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        # 这里的input_dim是vocab的长度，用来初始化一个input_dim x embedding_dim的矩阵，每个word学习为一个向量表示\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src):\n",
    "        # embedded的维度是[max_length, batch_size, embedding_dim]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # outputs 是最后一层LSTM的hidden输出，共有max_length个hidden，每个hidden的输出是一个hidden_size的向量\n",
    "        # 维度是[max_length, batch_size, num_directions x hidden_size]\n",
    "        # hidden 是每层LSTM最后一个hidden的输出，共有n_layers个hidden，每个hidden的输出是一个hidden_size的向量\n",
    "        # 维度是[n_layers x num_directions, batch_size, hidden_size]\n",
    "        # cell 是cell state，和hidden一起生成，维度相同\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef04f509-9a24-46ab-b02c-a62da12e035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        # 输出的维度是vocablary的维度，每个token的预测值\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input [1, batch_size] seq_length是1\n",
    "        input = input.unsqueeze(0)\n",
    "        # embedded [1, batch_size, embedding_dim]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # output [1, batch_size, hidden_dim]\n",
    "        # hidden [n_layers x n_directions, batch_size, hidden_size]--这里的n_directions是1\n",
    "        # cell 的维度和hidden 相同\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # 压掉加上的一个维度\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4a1642-4366-4722-8f14-9e8da055a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert( \n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert(\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"N_layers dimensions of encoder and decoder must be equal!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # trg [seq_length, batch_size]\n",
    "        batch_size = src.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # 输出每组预测值\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        # input 取batch中每个seq的第一个token\n",
    "        input = trg[0, :] # 可以写成trg[0]\n",
    "        for t in range(1, trg_length):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            # output [batch_size, vocabs_size] \n",
    "            # argmax(1) 每行最大值的索引，batch_size的预测word的vocab索引\n",
    "            top1 = output.argmax(1)\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b860847-ae1a-4123-9282-65233619595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(de_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model = Seq2seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81eec7a3-17d0-403c-91c5-feb933b40602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化权重\n",
    "def init_weights(m):\n",
    "    # 模型里的参数（权重和bias）初始化\n",
    "    for name, param in m.named_parameters():\n",
    "        # 初始化为-0.08~0.08的均匀分布\n",
    "        # 函数名后的_表示函数对参数进行本地操作，直接修改参数并不返回一个副本\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "# 将函数应用到函数的每个子模块\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7f62cce-6435-4276-9db7-55c2ce058979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,898,501 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    # numel() tensor方法number of element\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f08d6e92-3cc0-448a-ab41-e6235c13c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a730ece9-2075-47c7-b9b3-477b49638985",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18873fe5-688c-4fcc-966f-7d79567b8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        # src [seq_length, batch_size]\n",
    "        src = batch['de_ids'].to(device)\n",
    "        trg = batch['en_ids'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # output [trg_length, batch_size, trg_vocab_size]\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        output_dim = output.shape[-1]\n",
    "        # 第一个恒为0，去掉避免计算loss\n",
    "        # 拉平为[(trg_length-1) x batch_size, trg_vocab_size]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # trg [(trg_length-1) x batch_size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # 这里传入的output每个元素是一个未经softmax的向量，向量的每个分量值是每个类别的分数\n",
    "        loss = criterion(output, trg)\n",
    "        # 计算梯度\n",
    "        loss.backward()\n",
    "        # 裁剪梯度，防止梯度爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52d54276-7565-4861-9318-c47fc10b2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch['de_ids'].to(device)\n",
    "            trg = batch['en_ids'].to(device)\n",
    "            # 设置不用teacher_forcing\n",
    "            output = model(src, trg, 0)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44249946-ddaf-4d7d-a51c-14ed41fc69f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▍                                                                                    | 1/10 [05:02<45:21, 302.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  5.033 | Train PPL:153.356\n",
      "\tValid_loss:  4.917 | Valid PPL:136.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▊                                                                           | 2/10 [10:59<44:38, 334.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  4.384 | Train PPL: 80.185\n",
      "\tValid_loss:  4.703 | Valid PPL:110.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▏                                                                 | 3/10 [16:58<40:20, 345.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  4.107 | Train PPL: 60.776\n",
      "\tValid_loss:  4.550 | Valid PPL: 94.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▌                                                        | 4/10 [22:46<34:38, 346.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  3.895 | Train PPL: 49.174\n",
      "\tValid_loss:  4.326 | Valid PPL: 75.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████                                               | 5/10 [28:39<29:05, 349.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  3.702 | Train PPL: 40.546\n",
      "\tValid_loss:  4.277 | Valid PPL: 72.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████▍                                     | 6/10 [41:47<33:12, 498.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  3.524 | Train PPL: 33.935\n",
      "\tValid_loss:  4.108 | Valid PPL: 60.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████▊                            | 7/10 [58:21<33:00, 660.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  3.396 | Train PPL: 29.841\n",
      "\tValid_loss:  4.002 | Valid PPL: 54.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████▌                  | 8/10 [1:14:54<25:32, 766.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  3.206 | Train PPL: 24.682\n",
      "\tValid_loss:  3.930 | Valid PPL: 50.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████████████▊         | 9/10 [1:31:25<13:56, 836.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  3.076 | Train PPL: 21.681\n",
      "\tValid_loss:  3.829 | Valid PPL: 45.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 10/10 [1:48:05<00:00, 648.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain_loss:  2.962 | Train PPL: 19.341\n",
      "\tValid_loss:  3.739 | Valid PPL: 42.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model, \n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    print(f\"\\tTrain_loss:{train_loss:7.3f} | Train PPL:{np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid_loss:{valid_loss:7.3f} | Valid PPL:{np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a6e66d4-dfd9-4f25-afa9-375ccc261ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest_loss:  3.767 | Test PPL: 43.239\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "print(f\"\\tTest_loss:{test_loss:7.3f} | Test PPL:{np.exp(test_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "875c2745-4b48-4b50-897d-54ee21be8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 若sentence是字符串，转化为token\n",
    "        if isinstance(sentence, type(str)):\n",
    "            tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = de_vocab.lookup_indices(tokens)\n",
    "        # 加上一个维度，batch dimension\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        hidden, cell = model.encoder(tensor)\n",
    "        # 循环传入输入，一个接一个地生成单词\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
    "            # 预测的idx\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        tokens = en_vocab.lookup_tokens(inputs)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b58955e1-e5f2-47d7-983b-d89b4a632438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.',\n",
       " 'A man in an orange hat starring at something.')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[0][\"de\"]\n",
    "expected_translation = test_data[0][\"en\"]\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19adbbb6-9d35-4323-a33d-db5a23d372f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'a',\n",
       " 'man',\n",
       " 'with',\n",
       " 'a',\n",
       " 'white',\n",
       " 'hat',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'at',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab, \n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device\n",
    ")\n",
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e914083-6e09-4814-9a61-70c8be7988c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:25<00:00, 39.08it/s]\n"
     ]
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"de\"],\n",
    "        model,\n",
    "        en_nlp,\n",
    "        de_nlp,\n",
    "        en_vocab,\n",
    "        de_vocab,\n",
    "        lower,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "    ) for example in tqdm.tqdm(test_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40095ebd-cd23-4db3-93e6-29d65a3e842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1534a89edbe546dba04219ec036fccd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b6b6be282a4cabaaad82c7e9968c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838b8386e918408cb9e7a94e79631601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bleu = evaluate.load('bleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "325a3068-a280-47e4-a867-6d8539acb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "references = [[example['en']] for example in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "021365bf-5516-41f3-99d3-7925e5e6d9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a man with a white hat is looking at .',\n",
       " ['A man in an orange hat starring at something.'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0], references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a48b4a42-e022-4fd6-8905-c965b1b8edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_fn(nlp, lower):\n",
    "    def tokenizer_fn(s):\n",
    "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        return tokens\n",
    "    return tokenizer_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ebea4613-b5b1-43fd-9b8c-efb764a2ca1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 'man', 'with', 'a', 'white', 'hat', 'is', 'looking', 'at', '.'],\n",
       " ['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)\n",
    "tokenizer_fn(predictions[0]), tokenizer_fn(references[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f00804f-040c-4079-b211-90a80bf17a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bleu.compute(\n",
    "    predictions=predictions,\n",
    "    references=references,\n",
    "    tokenizer=tokenizer_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03ecac80-adcf-4a70-9844-fa1e1dbe4669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.13863526787905198,\n",
       " 'precisions': [0.483822601010101,\n",
       "  0.1949965729952022,\n",
       "  0.09464017991004497,\n",
       "  0.0467328370554177],\n",
       " 'brevity_penalty': 0.9699983984332067,\n",
       " 'length_ratio': 0.9704395772706387,\n",
       " 'translation_length': 12672,\n",
       " 'reference_length': 13058}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d9406-0eba-4e40-86d5-58e4b4247336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
